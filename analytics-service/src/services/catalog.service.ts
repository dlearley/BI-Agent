import { db } from '../config/database';
import { 
  Dataset, 
  Column, 
  ColumnStats, 
  PIIType, 
  PIIDetectionResult, 
  ColumnLineage,
  DiscoveryRequest,
  ProfileRequest,
  FreshnessInfo
} from '../types';
import { PoolClient } from 'pg';
import logger from '../utils/logger';

export class CatalogService {
  private readonly piiPatterns: Record<string, RegExp[]> = {
    [PIIType.EMAIL]: [/^[^\s@]+@[^\s@]+\.[^\s@]+$/],
    [PIIType.PHONE]: [/^[\d\-\(\)\s\+]+$/, /^[\d]{10}$/, /^[\d]{3}-[\d]{3}-[\d]{4}$/],
    [PIIType.SSN]: [/^[\d]{3}-[\d]{2}-[\d]{4}$/],
    [PIIType.CREDIT_CARD]: [/^[\d]{4}-[\d]{4}-[\d]{4}-[\d]{4}$/, /^[\d]{16}$/],
    [PIIType.DATE_OF_BIRTH]: [/^\d{4}-\d{2}-\d{2}$/, /^\d{2}\/\d{2}\/\d{4}$/],
  };

  private readonly piiFieldNames: Record<PIIType, RegExp[]> = {
    [PIIType.EMAIL]: [/email/i, /mail/i],
    [PIIType.PHONE]: [/phone/i, /phonenumber/i, /contact/i, /telephone/i],
    [PIIType.SSN]: [/ssn/i, /social_security/i, /socialsecurity/i],
    [PIIType.CREDIT_CARD]: [/card/i, /credit/i, /payment/i, /cardnumber/i],
    [PIIType.NAME]: [/^name$/i, /first_name/i, /last_name/i, /full_name/i, /username/i],
    [PIIType.ADDRESS]: [/address/i, /street/i, /city/i, /state/i, /zip/i, /postal/i],
    [PIIType.DATE_OF_BIRTH]: [/dob/i, /birth/i, /birthdate/i],
    [PIIType.DRIVER_LICENSE]: [/driver.*license/i, /dl_number/i],
    [PIIType.PASSPORT]: [/passport/i],
    [PIIType.HEALTH_ID]: [/patient_id/i, /medical_id/i, /health_id/i, /mrn/i],
    [PIIType.MEDICAL_RECORD]: [/medical/i, /diagnosis/i, /prescription/i, /procedure/i],
    [PIIType.UNKNOWN]: [/secret/i, /private/i, /confidential/i],
  };

  async discoverSchema(organizationId: string, request: DiscoveryRequest): Promise<Dataset[]> {
    try {
      const connector = await db.queryOne<any>(
        'SELECT * FROM data_connectors WHERE id = $1 AND organization_id = $2',
        [request.connector_id, organizationId]
      );

      if (!connector) {
        throw new Error(`Connector ${request.connector_id} not found`);
      }

      const datasets: Dataset[] = [];

      if (connector.type === 'postgresql') {
        const discoverredDatasets = await this.discoverPostgresql(connector, request);
        datasets.push(...discoverredDatasets);
      } else if (connector.type === 'mysql') {
        const discoveredDatasets = await this.discoverMysql(connector, request);
        datasets.push(...discoveredDatasets);
      } else if (connector.type === 'bigquery') {
        const discoveredDatasets = await this.discoverBigQuery(connector, request);
        datasets.push(...discoveredDatasets);
      } else {
        throw new Error(`Connector type ${connector.type} not yet supported`);
      }

      // Store discovered datasets
      for (const dataset of datasets) {
        await this.upsertDataset(organizationId, dataset);
      }

      logger.info('Schema discovery completed', {
        organizationId,
        connectorId: request.connector_id,
        datasetsDiscovered: datasets.length,
      });

      return datasets;
    } catch (error) {
      const message = error instanceof Error ? error.message : 'Unknown error';
      logger.error('Schema discovery failed', { error: message });
      throw error;
    }
  }

  private async discoverPostgresql(connector: any, request: DiscoveryRequest): Promise<Dataset[]> {
    const config = connector.config || {};
    const datasets: Dataset[] = [];

    try {
      const schemaQuery = `
        SELECT table_schema, table_name, table_type
        FROM information_schema.tables
        WHERE table_schema NOT IN ('pg_catalog', 'information_schema', 'pg_temp')
        ${request.schema_names?.length ? `AND table_schema = ANY($1)` : ''}
        ${request.table_patterns?.length ? `AND table_name LIKE ANY($${request.schema_names?.length ? 2 : 1})` : ''}
        ORDER BY table_schema, table_name
      `;

      const params = [];
      if (request.schema_names?.length) params.push(request.schema_names);
      if (request.table_patterns?.length) params.push(request.table_patterns.map(p => `%${p}%`));

      const tables = await db.query<any>(schemaQuery, params);

      for (const table of tables) {
        const columnQuery = `
          SELECT column_name, data_type, is_nullable, numeric_precision, numeric_scale
          FROM information_schema.columns
          WHERE table_schema = $1 AND table_name = $2
          ORDER BY ordinal_position
        `;

        const columns = await db.query<any>(columnQuery, [table.table_schema, table.table_name]);

        const dataset: Dataset = {
          id: '', // Will be generated by DB
          organization_id: connector.organization_id,
          connector_id: connector.id,
          name: table.table_name,
          schema_name: table.table_schema,
          table_name: table.table_name,
          row_count: 0,
          stats_json: {},
          freshness_sla_hours: 24,
          created_at: new Date(),
          updated_at: new Date(),
          columns: columns.map(col => ({
            id: '',
            dataset_id: '',
            column_name: col.column_name,
            column_type: col.data_type,
            is_nullable: col.is_nullable === 'YES',
            stats_json: {
              null_count: 0,
              distinct_count: 0,
              data_type: col.data_type,
              precision: col.numeric_precision,
              scale: col.numeric_scale,
            },
            is_pii: false,
            created_at: new Date(),
            updated_at: new Date(),
          })),
        };

        datasets.push(dataset);
      }
    } catch (error) {
      const message = error instanceof Error ? error.message : 'Unknown error';
      logger.error('PostgreSQL discovery failed', { error: message });
      throw error;
    }

    return datasets;
  }

  private async discoverMysql(connector: any, request: DiscoveryRequest): Promise<Dataset[]> {
    logger.warn('MySQL discovery not yet implemented');
    return [];
  }

  private async discoverBigQuery(connector: any, request: DiscoveryRequest): Promise<Dataset[]> {
    logger.warn('BigQuery discovery not yet implemented');
    return [];
  }

  private async upsertDataset(organizationId: string, dataset: Dataset): Promise<Dataset> {
    const sql = `
      INSERT INTO datasets (
        organization_id, connector_id, name, schema_name, table_name,
        stats_json, freshness_sla_hours, last_discovered_at, updated_at
      ) VALUES ($1, $2, $3, $4, $5, $6, $7, NOW(), NOW())
      ON CONFLICT (organization_id, connector_id, schema_name, table_name)
      DO UPDATE SET
        stats_json = EXCLUDED.stats_json,
        last_discovered_at = NOW(),
        updated_at = NOW()
      RETURNING id, organization_id, connector_id, name, schema_name, table_name,
        row_count, stats_json, freshness_sla_hours, last_discovered_at,
        last_profiled_at, created_at, updated_at
    `;

    const result = await db.queryOne<Dataset>(sql, [
      organizationId,
      dataset.connector_id,
      dataset.name,
      dataset.schema_name || null,
      dataset.table_name,
      JSON.stringify(dataset.stats_json || {}),
      dataset.freshness_sla_hours,
    ]);

    if (!result) {
      throw new Error('Failed to upsert dataset');
    }

    // Upsert columns
    if (dataset.columns && dataset.columns.length > 0) {
      for (const column of dataset.columns) {
        await this.upsertColumn(result.id, column);
      }
      result.columns = await this.getDatasetColumns(result.id);
    }

    return result;
  }

  private async upsertColumn(datasetId: string, column: Column): Promise<Column> {
    const sql = `
      INSERT INTO columns (
        dataset_id, column_name, column_type, is_nullable, stats_json, updated_at
      ) VALUES ($1, $2, $3, $4, $5, NOW())
      ON CONFLICT (dataset_id, column_name)
      DO UPDATE SET
        column_type = EXCLUDED.column_type,
        is_nullable = EXCLUDED.is_nullable,
        stats_json = EXCLUDED.stats_json,
        updated_at = NOW()
      RETURNING id, dataset_id, column_name, column_type, is_nullable, stats_json, is_pii, pii_type, pii_confidence, created_at, updated_at
    `;

    const result = await db.queryOne<Column>(sql, [
      datasetId,
      column.column_name,
      column.column_type,
      column.is_nullable,
      JSON.stringify(column.stats_json || {}),
    ]);

    if (!result) {
      throw new Error('Failed to upsert column');
    }

    return result;
  }

  async profileDataset(organizationId: string, datasetId: string, detectPII: boolean = true): Promise<Dataset> {
    const dataset = await db.queryOne<any>(
      `SELECT d.*, c.id as connector_id_val, c.config as connector_config, c.type as connector_type
       FROM datasets d
       JOIN data_connectors c ON d.connector_id = c.id
       WHERE d.id = $1 AND d.organization_id = $2`,
      [datasetId, organizationId]
    );

    if (!dataset) {
      throw new Error(`Dataset ${datasetId} not found`);
    }

    try {
      // Profile columns
      const columns = await db.query<any>(
        'SELECT * FROM columns WHERE dataset_id = $1',
        [datasetId]
      );

      let rowCount = 0;
      const connector = await db.queryOne<any>(
        'SELECT * FROM data_connectors WHERE id = $1',
        [dataset.connector_id]
      );

      if (connector && connector.type === 'postgresql') {
        rowCount = await this.getTableRowCount(connector, dataset.schema_name, dataset.table_name);
      }

      for (const column of columns) {
        if (connector && connector.type === 'postgresql') {
          const stats = await this.profilePostgresqlColumn(
            connector,
            dataset.schema_name,
            dataset.table_name,
            column.column_name,
            column.column_type
          );

          let piiResult: PIIDetectionResult = { is_pii: false, confidence: 0 };
          if (detectPII) {
            piiResult = this.detectPII(column.column_name, column.column_type, []);
          }

          await db.query(
            `UPDATE columns SET stats_json = $1, is_pii = $2, pii_type = $3, pii_confidence = $4, updated_at = NOW()
             WHERE id = $5`,
            [
              JSON.stringify(stats),
              piiResult.is_pii,
              piiResult.pii_type || null,
              piiResult.confidence,
              column.id,
            ]
          );
        }
      }

      // Update dataset stats
      await db.query(
        `UPDATE datasets SET row_count = $1, last_profiled_at = NOW(), updated_at = NOW() WHERE id = $2`,
        [rowCount, datasetId]
      );

      logger.info('Dataset profiling completed', { organizationId, datasetId });

      return (await db.queryOne<Dataset>(
        'SELECT * FROM datasets WHERE id = $1',
        [datasetId]
      ))!;
    } catch (error) {
      const message = error instanceof Error ? error.message : 'Unknown error';
      logger.error('Dataset profiling failed', { error: message, datasetId });
      throw error;
    }
  }

  private async getTableRowCount(connector: any, schemaName: string, tableName: string): Promise<number> {
    const escapedSchema = schemaName ? `"${schemaName}"` : 'public';
    const escapedTable = `"${tableName}"`;
    const sql = `SELECT COUNT(*) as count FROM ${escapedSchema}.${escapedTable}`;

    try {
      const result = await db.queryOne<any>(sql);
      return result?.count || 0;
    } catch (error) {
      logger.warn('Failed to get row count', { schemaName, tableName });
      return 0;
    }
  }

  private async profilePostgresqlColumn(
    connector: any,
    schemaName: string | undefined,
    tableName: string,
    columnName: string,
    columnType: string
  ): Promise<ColumnStats> {
    const escapedSchema = schemaName ? `"${schemaName}"` : 'public';
    const escapedTable = `"${tableName}"`;
    const escapedColumn = `"${columnName}"`;

    try {
      const sql = `
        SELECT
          COUNT(*) FILTER (WHERE ${escapedColumn} IS NULL) as null_count,
          COUNT(DISTINCT ${escapedColumn}) as distinct_count,
          MIN(${escapedColumn}::text) as min_value,
          MAX(${escapedColumn}::text) as max_value,
          AVG(CAST(${escapedColumn} AS FLOAT)) as avg_value
        FROM ${escapedSchema}.${escapedTable}
      `;

      const result = await db.queryOne<any>(sql);

      return {
        null_count: result?.null_count || 0,
        distinct_count: result?.distinct_count || 0,
        min_value: result?.min_value,
        max_value: result?.max_value,
        avg_value: result?.avg_value ? parseFloat(result.avg_value) : undefined,
        data_type: columnType,
      };
    } catch (error) {
      logger.warn('Failed to profile column', { columnName, tableName });
      return {
        null_count: 0,
        distinct_count: 0,
        data_type: columnType,
      };
    }
  }

  detectPII(columnName: string, columnType: string, sampleValues: (string | number)[]): PIIDetectionResult {
    let highestConfidence = 0;
    let detectedType: PIIType | undefined;

    // Check field name patterns
    for (const [piiType, patterns] of Object.entries(this.piiFieldNames)) {
      for (const pattern of patterns) {
        if (pattern.test(columnName)) {
          if (0.8 > highestConfidence) {
            highestConfidence = 0.8;
            detectedType = piiType as PIIType;
          }
          break;
        }
      }
    }

    // Check value patterns if available
    if (sampleValues.length > 0) {
      for (const [piiType, patterns] of Object.entries(this.piiPatterns)) {
        for (const pattern of patterns) {
          const matches = sampleValues.filter(v => pattern.test(String(v))).length;
          const confidence = matches / Math.max(sampleValues.length, 1);
          if (confidence > highestConfidence) {
            highestConfidence = confidence;
            detectedType = piiType as PIIType;
          }
        }
      }
    }

    // Determine if it's likely PII
    const isPII = highestConfidence >= 0.7;

    return {
      is_pii: isPII,
      pii_type: isPII ? detectedType : undefined,
      confidence: highestConfidence,
      pattern_matched: isPII ? detectedType : undefined,
    };
  }

  async getDatasets(organizationId: string, limit: number = 100, offset: number = 0): Promise<{ datasets: Dataset[]; total: number }> {
    const total = await db.queryOne<any>(
      'SELECT COUNT(*) as count FROM datasets WHERE organization_id = $1',
      [organizationId]
    );

    const datasets = await db.query<Dataset>(
      `SELECT * FROM datasets WHERE organization_id = $1 ORDER BY created_at DESC LIMIT $2 OFFSET $3`,
      [organizationId, limit, offset]
    );

    return {
      datasets,
      total: total?.count || 0,
    };
  }

  async getDataset(organizationId: string, datasetId: string): Promise<Dataset | null> {
    const dataset = await db.queryOne<Dataset>(
      'SELECT * FROM datasets WHERE id = $1 AND organization_id = $2',
      [datasetId, organizationId]
    );

    if (dataset) {
      dataset.columns = await this.getDatasetColumns(datasetId);
    }

    return dataset || null;
  }

  private async getDatasetColumns(datasetId: string): Promise<Column[]> {
    return db.query<Column>(
      'SELECT * FROM columns WHERE dataset_id = $1 ORDER BY column_name',
      [datasetId]
    );
  }

  async getColumns(organizationId: string, filters?: { is_pii?: boolean; pii_type?: PIIType }): Promise<Column[]> {
    let sql = `
      SELECT c.* FROM columns c
      JOIN datasets d ON c.dataset_id = d.id
      WHERE d.organization_id = $1
    `;

    const params: any[] = [organizationId];
    let paramIndex = 2;

    if (filters?.is_pii !== undefined) {
      sql += ` AND c.is_pii = $${paramIndex}`;
      params.push(filters.is_pii);
      paramIndex++;
    }

    if (filters?.pii_type) {
      sql += ` AND c.pii_type = $${paramIndex}`;
      params.push(filters.pii_type);
      paramIndex++;
    }

    sql += ' ORDER BY c.column_name';

    return db.query<Column>(sql, params);
  }

  async computeFreshness(organizationId: string): Promise<FreshnessInfo[]> {
    const datasets = await db.query<any>(
      `SELECT id, table_name, freshness_sla_hours, last_profiled_at
       FROM datasets
       WHERE organization_id = $1`,
      [organizationId]
    );

    return datasets.map(ds => {
      const lastUpdated = ds.last_profiled_at || ds.created_at;
      const ageHours = (Date.now() - new Date(lastUpdated).getTime()) / (1000 * 60 * 60);
      const isFresh = ageHours <= (ds.freshness_sla_hours || 24);

      return {
        table_name: ds.table_name,
        sla_hours: ds.freshness_sla_hours,
        last_updated: lastUpdated,
        age_hours: Math.round(ageHours * 10) / 10,
        is_fresh: isFresh,
      };
    });
  }

  async addLineage(
    organizationId: string,
    sourceColumnId: string,
    targetColumnId: string | undefined,
    sourceTable: string,
    targetTable: string,
    lineageType: 'upstream' | 'downstream' | 'sibling' = 'upstream'
  ): Promise<ColumnLineage> {
    const sql = `
      INSERT INTO column_lineage (
        organization_id, source_column_id, target_column_id, source_table, target_table, lineage_type, updated_at
      ) VALUES ($1, $2, $3, $4, $5, $6, NOW())
      ON CONFLICT (source_column_id, target_column_id, source_table, target_table, lineage_type) DO NOTHING
      RETURNING id, organization_id, source_column_id, target_column_id, source_table, target_table, lineage_type, created_at, updated_at
    `;

    const result = await db.queryOne<ColumnLineage>(sql, [
      organizationId,
      sourceColumnId,
      targetColumnId || null,
      sourceTable,
      targetTable,
      lineageType,
    ]);

    if (!result) {
      throw new Error('Failed to add lineage');
    }

    return result;
  }

  async getLineage(organizationId: string, columnId: string): Promise<{ upstream: ColumnLineage[]; downstream: ColumnLineage[] }> {
    const upstream = await db.query<ColumnLineage>(
      'SELECT * FROM column_lineage WHERE organization_id = $1 AND target_column_id = $2 AND lineage_type = $3',
      [organizationId, columnId, 'upstream']
    );

    const downstream = await db.query<ColumnLineage>(
      'SELECT * FROM column_lineage WHERE organization_id = $1 AND source_column_id = $2 AND lineage_type = $3',
      [organizationId, columnId, 'downstream']
    );

    return { upstream, downstream };
  }
}

export const catalogService = new CatalogService();
